[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lab 6",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(ggthemes)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.0     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(glue)"
  },
  {
    "objectID": "index.html#question1",
    "href": "index.html#question1",
    "title": "Lab 6",
    "section": "Question#1",
    "text": "Question#1\n\nWhat does zero_q_freq represent?\nThe CAMELS dataset doc says that zero_q_freq is the fraction of days with zero stream flow over the observational period. So this means it is a measure of how often a stream at a given site runs dry.\n\nclim &lt;- read_delim(\"data/camels_clim.txt\", delim = \";\")\n\nRows: 671 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (3): gauge_id, high_prec_timing, low_prec_timing\ndbl (9): p_mean, pet_mean, p_seasonality, frac_snow, aridity, high_prec_freq...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ngeol &lt;- read_delim(\"data/camels_geol.txt\", delim = \";\")\n\nRows: 671 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (3): gauge_id, geol_1st_class, geol_2nd_class\ndbl (5): glim_1st_class_frac, glim_2nd_class_frac, carbonate_rocks_frac, geo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhydro &lt;- read_delim(\"data/camels_hydro.txt\", delim = \";\")\n\nRows: 671 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (1): gauge_id\ndbl (13): q_mean, runoff_ratio, slope_fdc, baseflow_index, stream_elas, q5, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsoil &lt;- read_delim(\"data/camels_soil.txt\", delim = \";\")\n\nRows: 671 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (1): gauge_id\ndbl (11): soil_depth_pelletier, soil_depth_statsgo, soil_porosity, soil_cond...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntopo &lt;- read_delim(\"data/camels_topo.txt\", delim = \";\")\n\nRows: 671 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (1): gauge_id\ndbl (6): gauge_lat, gauge_lon, elev_mean, slope_mean, area_gages2, area_geos...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nvege &lt;- read_delim(\"data/camels_vege.txt\", delim = \";\")\n\nRows: 671 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): gauge_id, dom_land_cover\ndbl (8): frac_forest, lai_max, lai_diff, gvf_max, gvf_diff, dom_land_cover_f...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncamels &lt;- reduce(list(clim, geol, hydro, soil, topo, vege), full_join, by = \"gauge_id\")\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map() +\n  labs(title = \"CAMELS Sites Colored by Mean Flow (q_mean)\",\n       x = \"Longitude\", y = \"Latitude\",\n       color = \"Mean Flow\")"
  },
  {
    "objectID": "index.html#question-2",
    "href": "index.html#question-2",
    "title": "Lab 6",
    "section": "Question #2",
    "text": "Question #2\n\nlibrary(patchwork)\n\nmap_p &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray60\") +\n  geom_point(aes(color = p_mean), size = 2) +\n  scale_color_viridis_c(option = \"D\") +\n  coord_fixed(1.3) +  # &lt;- this is the fix!\n  ggthemes::theme_map() +\n  labs(title = \"Mean Precipitation (p_mean)\",\n       color = \"mm/day\")\n\nmap_a &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray60\") +\n  geom_point(aes(color = aridity), size = 2) +\n  scale_color_viridis_c(option = \"C\") +\n  coord_fixed(1.3) +  # &lt;- fix here too\n  ggthemes::theme_map() +\n  labs(title = \"Aridity Index (PET / P)\",\n       color = \"Aridity\")\n\nmap_p + map_a"
  },
  {
    "objectID": "index.html#model-building",
    "href": "index.html#model-building",
    "title": "Lab 6",
    "section": "Model Building",
    "text": "Model Building\n\nlibrary(tidymodels)\n\n\ncamels_mod &lt;- camels %&gt;%\n  select(where(is.numeric)) %&gt;%\n  drop_na()\n\n\nset.seed(330)\nsplit &lt;- initial_split(camels_mod, prop = 0.8)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\n\n\nrec &lt;- recipe(q_mean ~ ., data = train) %&gt;%\n  step_normalize(all_predictors())\n\n\nlm_mod &lt;- linear_reg() %&gt;% set_engine(\"lm\")\nrf_mod &lt;- rand_forest(mode = \"regression\") %&gt;% set_engine(\"ranger\")\nxgb_mod &lt;- boost_tree(mode = \"regression\") %&gt;% set_engine(\"xgboost\")\n\n\nmodels &lt;- workflow_set(\n  preproc = list(base = rec),\n  models = list(LM = lm_mod, RF = rf_mod, XGB = xgb_mod)\n)\n\nresamples &lt;- vfold_cv(train, v = 5)\n\n\nresults &lt;- models %&gt;%\n  workflow_map(\"fit_resamples\", resamples = resamples, metrics = metric_set(rmse, rsq))\n\n\ncollect_metrics(results) %&gt;% \n  select(wflow_id, .metric, mean, std_err)\n\n# A tibble: 6 × 4\n  wflow_id .metric  mean std_err\n  &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 base_LM  rmse    0.167 0.00498\n2 base_LM  rsq     0.988 0.00120\n3 base_RF  rmse    0.283 0.0323 \n4 base_RF  rsq     0.971 0.00424\n5 base_XGB rmse    0.207 0.0249 \n6 base_XGB rsq     0.982 0.00338\n\n\n\nfinal_lm &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(lm_mod) %&gt;%\n  fit(data = train)\n\n\nlm_preds &lt;- predict(final_lm, test) %&gt;%\n  bind_cols(test)\n\nmetrics(lm_preds, truth = q_mean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.148\n2 rsq     standard       0.989\n3 mae     standard       0.104\n\nggplot(lm_preds, aes(x = q_mean, y = .pred)) +\n  geom_point(alpha = 0.6) +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Test Set: Predicted vs Observed q_mean (Linear Model)\",\n       x = \"Observed q_mean\",\n       y = \"Predicted q_mean\")"
  },
  {
    "objectID": "index.html#question-3",
    "href": "index.html#question-3",
    "title": "Lab 6",
    "section": "Question #3",
    "text": "Question #3\n\nlibrary(baguette)\n\nnn_mod &lt;- bag_mlp(mode = \"regression\") %&gt;%\n  set_engine(\"nnet\")\n\n\nmodels_all &lt;- workflow_set(\n  preproc = list(base = rec),\n  models = list(\n    LM = lm_mod,\n    RF = rf_mod,\n    XGB = xgb_mod,\n    NN = nn_mod\n  )\n)\n\n# Fit with cross-validation\nresults_all &lt;- models_all %&gt;%\n  workflow_map(\"fit_resamples\", resamples = resamples, metrics = metric_set(rmse, rsq))\n\n\ncollect_metrics(results_all) %&gt;%\n  select(wflow_id, .metric, mean, std_err)\n\n# A tibble: 8 × 4\n  wflow_id .metric  mean std_err\n  &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 base_LM  rmse    0.167 0.00498\n2 base_LM  rsq     0.988 0.00120\n3 base_RF  rmse    0.281 0.0371 \n4 base_RF  rsq     0.971 0.00512\n5 base_XGB rmse    0.207 0.0249 \n6 base_XGB rsq     0.982 0.00338\n7 base_NN  rmse    0.252 0.0146 \n8 base_NN  rsq     0.972 0.00302\n\n\nAfter adding a neural net model, I compared linear, RF, XGBoost, and NN. Linear regression still performed the best overall with the lowest RMSE and highest R². The neural net and XGBoost were close behind, but the simplicity and strong performance of the linear model makes it the best choice for this dataset."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "data/hyperparameter-tuning.html",
    "href": "data/hyperparameter-tuning.html",
    "title": "hyperparameter-tuning",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.0     ✔ yardstick    1.3.2\n✔ recipes      1.1.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\nlibrary(readxl)\nlibrary(skimr)\nlibrary(visdat)\nlibrary(ggthemes)\nlibrary(patchwork)\n\ndata_path &lt;- \"~/Desktop/ESS320/Lab_6/data/\"\n\nclim  &lt;- read_delim(paste0(data_path, \"camels_clim.txt\"), delim = \";\")\n\nRows: 671 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (3): gauge_id, high_prec_timing, low_prec_timing\ndbl (9): p_mean, pet_mean, p_seasonality, frac_snow, aridity, high_prec_freq...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ngeol  &lt;- read_delim(paste0(data_path, \"camels_geol.txt\"), delim = \";\")\n\nRows: 671 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (3): gauge_id, geol_1st_class, geol_2nd_class\ndbl (5): glim_1st_class_frac, glim_2nd_class_frac, carbonate_rocks_frac, geo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhydro &lt;- read_delim(paste0(data_path, \"camels_hydro.txt\"), delim = \";\")\n\nRows: 671 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (1): gauge_id\ndbl (13): q_mean, runoff_ratio, slope_fdc, baseflow_index, stream_elas, q5, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsoil  &lt;- read_delim(paste0(data_path, \"camels_soil.txt\"), delim = \";\")\n\nRows: 671 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (1): gauge_id\ndbl (11): soil_depth_pelletier, soil_depth_statsgo, soil_porosity, soil_cond...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntopo  &lt;- read_delim(paste0(data_path, \"camels_topo.txt\"), delim = \";\")\n\nRows: 671 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (1): gauge_id\ndbl (6): gauge_lat, gauge_lon, elev_mean, slope_mean, area_gages2, area_geos...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nvege  &lt;- read_delim(paste0(data_path, \"camels_vege.txt\"), delim = \";\")\n\nRows: 671 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (2): gauge_id, dom_land_cover\ndbl (8): frac_forest, lai_max, lai_diff, gvf_max, gvf_diff, dom_land_cover_f...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ncamels &lt;- reduce(\n  list(clim, geol, hydro, soil, topo, vege),\n  power_full_join,\n  by = \"gauge_id\"\n)\n\n\ncamels &lt;- reduce(\n  list(clim, geol, hydro, soil, topo, vege),\n  power_full_join,\n  by = \"gauge_id\"\n)\n\ncamels_clean &lt;- camels %&gt;%\n  mutate(dom_land_cover = str_trim(dom_land_cover)) %&gt;%\n  mutate(across(\n    .cols = -c(gauge_id, high_prec_timing, low_prec_timing, geol_1st_class, geol_2nd_class, dom_land_cover),\n    .fns = as.numeric\n  )) %&gt;%\n  filter(!is.na(gauge_lat), !is.na(gauge_lon)) %&gt;%\n  distinct()\n\ncamels_model &lt;- camels_clean %&gt;%\n  filter(!is.na(q_mean), !is.infinite(q_mean), q_mean &lt; 1e6) %&gt;%\n  select(where(is.numeric))\nsplit &lt;- initial_split(camels_model, prop = 0.8)\n\n\ncamels_model &lt;- camels_clean %&gt;%\n  filter(\n    !is.na(q_mean),\n    !is.infinite(q_mean),\n    q_mean &lt; 1e6  \n  ) %&gt;%\n  select(where(is.numeric))\n\n\nset.seed(330)\nsplit &lt;- initial_split(camels_model, prop = 0.8)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\n\n\nrec &lt;- recipe(q_mean ~ ., data = train) %&gt;%\n  step_rm(gauge_lat, gauge_lon) %&gt;%\n  step_impute_mean(all_predictors()) %&gt;%\n  step_normalize(all_predictors())\n\n\nfolds &lt;- vfold_cv(train, v = 10)\n\nlm_mod &lt;- linear_reg() %&gt;% set_engine(\"lm\")\nrf_mod &lt;- rand_forest(mode = \"regression\") %&gt;% set_engine(\"ranger\")\nxgb_mod &lt;- boost_tree(mode = \"regression\") %&gt;% set_engine(\"xgboost\")\n\n\nxgb_tune &lt;- boost_tree(\n  mode = \"regression\",\n  mtry = tune(),\n  trees = tune(),\n  min_n = tune()\n) %&gt;%\n  set_engine(\"xgboost\")\n\n\nwf_tune &lt;- workflow() %&gt;%\n  add_model(xgb_tune) %&gt;%\n  add_recipe(rec)\n\ndials &lt;- extract_parameter_set_dials(wf_tune)\ndials &lt;- finalize(dials, train)\n\nmy.grid &lt;- grid_latin_hypercube(dials, size = 25)\n\nWarning: `grid_latin_hypercube()` was deprecated in dials 1.3.0.\nℹ Please use `grid_space_filling()` instead.\n\nmodel_params &lt;- tune_grid(\n  wf_tune,\n  resamples = folds,\n  grid = my.grid,\n  metrics = metric_set(rmse, rsq, mae),\n  control = control_grid(save_pred = TRUE)\n)\n\nautoplot(model_params)\n\n\n\n\n\n\n\ncollect_metrics(model_params)\n\n# A tibble: 75 × 9\n    mtry trees min_n .metric .estimator  mean     n std_err .config             \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1     2  1072    38 mae     standard   0.293    10 0.0156  Preprocessor1_Model…\n 2     2  1072    38 rmse    standard   0.452    10 0.0269  Preprocessor1_Model…\n 3     2  1072    38 rsq     standard   0.917    10 0.0141  Preprocessor1_Model…\n 4     4   228    12 mae     standard   0.213    10 0.0112  Preprocessor1_Model…\n 5     4   228    12 rmse    standard   0.363    10 0.0256  Preprocessor1_Model…\n 6     4   228    12 rsq     standard   0.953    10 0.00619 Preprocessor1_Model…\n 7     6  1712    25 mae     standard   0.203    10 0.0143  Preprocessor1_Model…\n 8     6  1712    25 rmse    standard   0.342    10 0.0297  Preprocessor1_Model…\n 9     6  1712    25 rsq     standard   0.958    10 0.00463 Preprocessor1_Model…\n10     8  1982    31 mae     standard   0.207    10 0.0166  Preprocessor1_Model…\n# ℹ 65 more rows\n\nshow_best(model_params, metric = \"mae\")\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1    23   556     8 mae     standard   0.100    10 0.00958 Preprocessor1_Model11\n2    32  1282     6 mae     standard   0.102    10 0.00575 Preprocessor1_Model15\n3    35  1144     4 mae     standard   0.104    10 0.00729 Preprocessor1_Model17\n4    48  1451     8 mae     standard   0.107    10 0.00742 Preprocessor1_Model24\n5    33  1234    11 mae     standard   0.111    10 0.0123  Preprocessor1_Model16\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\nfinal_wf &lt;- finalize_workflow(wf_tune, hp_best)\n\n\ncollect_metrics(model_params)\n\n# A tibble: 75 × 9\n    mtry trees min_n .metric .estimator  mean     n std_err .config             \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1     2  1072    38 mae     standard   0.293    10 0.0156  Preprocessor1_Model…\n 2     2  1072    38 rmse    standard   0.452    10 0.0269  Preprocessor1_Model…\n 3     2  1072    38 rsq     standard   0.917    10 0.0141  Preprocessor1_Model…\n 4     4   228    12 mae     standard   0.213    10 0.0112  Preprocessor1_Model…\n 5     4   228    12 rmse    standard   0.363    10 0.0256  Preprocessor1_Model…\n 6     4   228    12 rsq     standard   0.953    10 0.00619 Preprocessor1_Model…\n 7     6  1712    25 mae     standard   0.203    10 0.0143  Preprocessor1_Model…\n 8     6  1712    25 rmse    standard   0.342    10 0.0297  Preprocessor1_Model…\n 9     6  1712    25 rsq     standard   0.958    10 0.00463 Preprocessor1_Model…\n10     8  1982    31 mae     standard   0.207    10 0.0166  Preprocessor1_Model…\n# ℹ 65 more rows\n\nshow_best(model_params, metric = \"mae\")\n\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1    23   556     8 mae     standard   0.100    10 0.00958 Preprocessor1_Model11\n2    32  1282     6 mae     standard   0.102    10 0.00575 Preprocessor1_Model15\n3    35  1144     4 mae     standard   0.104    10 0.00729 Preprocessor1_Model17\n4    48  1451     8 mae     standard   0.107    10 0.00742 Preprocessor1_Model24\n5    33  1234    11 mae     standard   0.111    10 0.0123  Preprocessor1_Model16\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\nfinal_wf &lt;- finalize_workflow(wf_tune, hp_best)\n\n\nfinal_fit &lt;- last_fit(final_wf, split)\npreds &lt;- collect_predictions(final_fit)\n\nggplot(preds, aes(x = q_mean, y = .pred)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"dodgerblue\") +\n  geom_abline(linetype = \"dashed\", color = \"gray30\") +\n  labs(\n    x = \"Observed q_mean\",\n    y = \"Predicted q_mean\",\n    title = \"Final Model: Observed vs Predicted\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nfinal_model &lt;- fit(final_wf, data = camels_model)\n\n# Predictions for map\npredicted_map &lt;- augment(final_model, camels_clean) %&gt;%\n  mutate(residual = (q_mean - .pred)^2)\n\n# Plot 1: Predicted q_mean\nmap_q &lt;- ggplot(predicted_map, aes(x = gauge_lon, y = gauge_lat)) +\n  geom_point(aes(color = .pred), size = 2) +\n  borders(\"state\", colour = \"gray70\") +\n  scale_color_viridis_c() +\n  ggthemes::theme_map() +\n  labs(title = \"Predicted q_mean\")\n\n# Plot 2: Residuals\nmap_resid &lt;- ggplot(predicted_map, aes(x = gauge_lon, y = gauge_lat)) +\n  geom_point(aes(color = residual), size = 2) +\n  borders(\"state\", colour = \"gray70\") +\n  scale_color_viridis_c() +\n  ggthemes::theme_map() +\n  labs(title = \"Prediction Residuals\")\n\n# Combine\nmap_q + map_resid\n\n\n\n\n\n\n\n\n\nglimpse(preds)\n\nRows: 134\nColumns: 5\n$ .pred   &lt;dbl&gt; 1.7613258, 2.1773000, 1.8203005, 2.1922755, 1.8064754, 1.97281…\n$ id      &lt;chr&gt; \"train/test split\", \"train/test split\", \"train/test split\", \"t…\n$ .row    &lt;int&gt; 1, 2, 3, 5, 9, 18, 19, 23, 27, 30, 35, 36, 37, 43, 44, 47, 56,…\n$ q_mean  &lt;dbl&gt; 1.6991545, 2.1730621, 1.8201075, 2.1828696, 1.8235506, 1.81168…\n$ .config &lt;chr&gt; \"Preprocessor1_Model1\", \"Preprocessor1_Model1\", \"Preprocessor1…"
  }
]